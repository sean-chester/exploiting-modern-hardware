/**
 * Introduction to multi-core analytics.
 * Sub-topics include the use of the OpenMP threading library
 * and the **parallel reduction** technique.
 *
 * Applying these techniques to a problem we used in the Branch Prediction lecture, the
 * _Sum Over Threshold_ problem. Given an input vector `v = <v_i>` and a threshold `t`,
 * determine `sum_{v_i\in v, v_i >= t}`
 *
 * For example, given the input <2, 3, 1, 8, 3, 4> and threshold 4, the response is:
 * 8 + 4 = 12.
 */

#include <iostream> // std::cout, std::endl
#include <chrono>   // std::chrono
#include <numeric>  // std::accumulate()
#include <omp.h>    // for multi-core parallelism

#include <vector>

// statically-defined input data
// #include "unsorted-small.hpp"
#include "unsorted-data.hpp"


namespace { // anonymous

/**
 * Branchless functor to add a value to a running sum iff the value is >= functor threshold
 */
template < typename T >
    struct branchless_sum
    {
        T const threshold;

        T operator ()( T const value ) const
        {
            // Avoid branch by multiplying value by the result of the condition (0 or 1)
            return value * ( value >= threshold );
        }
    };

} // namespace anonymous


namespace race_condition {

/**
 * Calculates the sum of all values in input_data[] that are above the given threshold.
 * Compared to yesterday's ILP lecture, this invokes branching, which creates an
 * entirely different bottleneck in the program (or path in the Intel top-down analysis method).
 */
template < typename T >
    T sum_over_threshold( T const threshold )
    {
        auto const n = sizeof( input_data ) / sizeof ( input_data[ 0 ] );
        auto sum = 0lu;

        #pragma omp parallel for schedule( static )
        for( auto i = 0lu; i < n; ++i )
        {
            sum += branchless_sum< T >{ threshold }( input_data[ i ] );
        }

        return sum; // Non-deterministic!
    }
} // namespace race_condition



namespace manual_parallel_reduction {

/**
 * Calculates the sum of all values in input_data[] that are above the given threshold.
 * Compared to yesterday's ILP lecture, this invokes branching, which creates an
 * entirely different bottleneck in the program (or path in the Intel top-down analysis method).
 */
template < typename T >
    T sum_over_threshold( T const threshold )
    {
        auto const n = sizeof( input_data ) / sizeof ( input_data[ 0 ] );
        auto const t = omp_get_max_threads();
        std::vector< uint64_t > sum( t, 0lu );

        #pragma omp parallel for schedule( static )
        for( auto i = 0lu; i < n; ++i )
        {
            auto const t = omp_get_thread_num();
            sum[ t ] += branchless_sum< T >{ threshold }( input_data[ i ] );
        }

        return std::accumulate( std::cbegin( sum ), std::cend( sum ), 0lu );
    }
} // namespace manual_parallel_reduction



namespace auto_parallel_reduction {

/**
 * Calculates the sum of all values in input_data[] that are above the given threshold.
 * Compared to yesterday's ILP lecture, this invokes branching, which creates an
 * entirely different bottleneck in the program (or path in the Intel top-down analysis method).
 */
template < typename T >
    T sum_over_threshold( T const threshold )
    {
        auto const n = sizeof( input_data ) / sizeof ( input_data[ 0 ] );
        auto sum = 0lu;

        #pragma omp parallel for reduction( +:sum )
        for( auto i = 0lu; i < n; ++i )
        {
            sum += branchless_sum< T >{ threshold }( input_data[ i ] );
        }

        return sum;
    }
} // namespace auto_parallel_reduction


int main( int argc, char ** argv )
{
    auto sum = 0lu;
    auto const benchmark_trials = 20000u;
    auto const threshold = 750llu;

    if( argc >= 2 )
    {
        // omp_set_num_threads() sets the global number of threads used by OpenMP
        // If this is not set, then it defaults to the number of cores on the machine
        // Here, we take the value from the first command line argument (`argv[ 1 ]`),
        // after converting it from ascii to int (the `atoi()` function).
        omp_set_num_threads( atoi( argv[ 1 ] ) );
    }

    auto const start_time = std::chrono::system_clock::now();

    for( auto i = 0u; i < benchmark_trials; ++i )
    {
        // Toggle example by changing namespace
        sum += race_condition::sum_over_threshold( threshold );
        // sum += manual_parallel_reduction::sum_over_threshold( threshold );
        // sum += auto_parallel_reduction::sum_over_threshold( threshold );
    }

    auto const end_time = std::chrono::system_clock::now();
    auto const elapsed_time = std::chrono::duration_cast< std::chrono::microseconds >( end_time - start_time );

    std::cout << "sum = " << ( sum / static_cast< float >( benchmark_trials ) ) << std::endl;
    std::cout << "average time per run: "
              << elapsed_time.count() / static_cast< float >( benchmark_trials )
              << " us" << std::endl;

    return 0;
}
