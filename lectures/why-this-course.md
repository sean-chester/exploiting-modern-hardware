# Notes re: Sutter articles, a.k.a., why this course?

 * Why these articles, did you understand them, representative of why these course skills are valuable
 * Who is Sutter, reputability of gray literature, temporal context of articles (predictions not research, op-ed)
 * What is a "Free Lunch"? What is Moore's Law? (transistor diagram, exponential miniaturisation of transistors)
   * To whom is it relevant? Killer apps (e.g., PS3, AR), relate to projects/papers in this course
     * Data Management is a killer app! (why?)
   * compute-intensive, compute-bound vs memory-bound (learn to diagnose which), memory wall (Drepper), relate to parallel scalability
     * paragraph on execution optimisation and cache, then on SSE
     * need to be compute-intensive to be parallel-friendly; why we will focus on making compute-bound before going to multicore
     * parallel-friendly = "expose parallelism"; what does that mean? (paragraph "juicy latent parallelism")
 * Why focus on performance so much, especially with MVP/agile/first-to-market market forces
   * Big Data hasn't gone away. Actually trend was always there, but the "free lunch" kept pace with it
   * not just the killer apps, numerous though they are; 2x efficient paragraph: cost savings -- what if only 10% better throughput?
 * What is "the Jungle"? (confused mess diagram), cloud vs multi-core vs gpgpu (and others?)
   * power wall (lunch diagram), dissipating heat
   * skinny vs fat cores, heterogeneity (big/fast diagram)
   * why not cloud instead of this course? (2 highlighted mines diagram); gpus in cloud
 * Where are we actually at, 8 years later? Docked mobiles with elasticity based on wifi range?
   * $1500/hr 30k node clouds in 2012?
   * my opinion: shortage of concurrency and optimised programming skills, parallel patterns not widely known
   * manufacturer's can come up with other approaches to the memory wall + more specialised units
 * how do you position yourself to have in-demand skills (in this context)? A Programmerâ€™s View paragraph; costs of concurrency paragraph
   * skills that are hard are in demand
   * most tech firms have _underutilised installed base_ of performance potential and cost savings (not just gpu, but other parallelism, too)
   * knowing how to make something more compute-bound so that it is more amenable to parallelisation
   * knowing how to expose parallelism where other people don't see it