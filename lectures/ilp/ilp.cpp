/**
 * A set of experiments designed to illustrate the effect of instruction-level parallelism (ILP).
 *
 * On an Intel Skylake processor, the float ADD operation has a throughput of one addition every
 * quarter clock cycle, but a latency of an entire cycle. There are also two ports (port 0 and port 1)
 * with floating point arithmetic functional units; so, in principle, an implementation with full ILP
 * should be able to run 4*2 = 8x faster than one without any ILP. Next time you contemplate the speedup
 * you can get from a 4-core machine, consider first how much each super-scalar processor can provide
 * on its own!
 */

#include <iostream> // std::cout, std::endl
#include <numeric>  // std::accumulate()
#include <chrono>   // std::chrono
#include <array>


/**
 * Naive (typical) implementation of a method that adds up val iterations number of times.
 *
 * @note Equivalent to `return val * iterations;`, but meant to demonstrate front-bound execution.
 */
template < typename T >
    T baseline( T const val, size_t const iterations )
    {
        T result = 0;

        for ( auto i = 0llu; i < iterations; ++i )
        {
            result += val;
        }

        return result;
    }

/**
 * Version of baseline() in which the loop has been unrolled 4x.
 */
template < typename T >
    T unrolled( T const val, size_t const iterations )
    {
        T result = 0;

        // Observe that we have four-fold fewer branches and additions = probably slightly faster
        // But doesn't address bottleneck of latencies on float addition
        for ( auto i = 0llu; i < iterations; i += 4 )
        {
            // Observe! Unrolling does not break the dependency chain!
            // The second line still cannot execute until after the first one
            // because it uses as an input operand the output result of the first operation.
            // The same is true of the 3rd and 4th instructions.
            // Despite the unrolling, this code is still sequential;
            // i.e., it lacks instruction-level parallelism (ILP) on the additions.
            result += val;
            result += val;
            result += val;
            result += val;
        }

        return result;
    }

/**
 * An instruction-level-parallel (ILP) version of the unrolled() method.
 */
template < typename T >
    T parallel(  T const val, size_t const iterations )
    {
        auto const loop_size = 4llu;

        // This is the key! To break the dependency, we accumulate in four separate
        // variables (grouped here in a c-style array initialised to zeroes).
        T result[ loop_size ] = {};

        // We gain from skipping four at a time, exactly as in unrolled()
        for ( auto c = 0llu; c < iterations; c += loop_size )
        {
            // But here, result[ 1 ] does not depend on the first instruction anymore
            // (which accumulates in result[ 0 ]!
            // This technique is called a "parallel reduction" and it *exposes* the ILP
            // so that the processor (or compiler) can take advantage of it.
            // TAKE NOTE! This is not the last time that we will a parallel reduction!
            result[ 0 ] += val;
            result[ 1 ] += val;
            result[ 2 ] += val;
            result[ 3 ] += val;
        }

        // At the end, we have to aggregate our "reduced" results from each register.
        // for this problem, each register only contains 1/4 of the result value. 
        return std::accumulate( result, result + loop_size, 0llu );
    }



int main()
{
    // To toggle between the three methods while still enabled an app-wide profiling
    // with the Linux `perf` tool, uncomment the specific function call that you want
    // to profile and then recompile.

    auto const iterations = 8000000000llu;
    auto const val_to_add = 2.0;
    auto const start_time = std::chrono::system_clock::now();

    auto const sum = baseline( val_to_add, iterations );
    // auto const sum = unrolled( val_to_add, iterations );
    // auto const sum = parallel( val_to_add, iterations );

    auto const end_time = std::chrono::system_clock::now();
    auto const elapsed_time = std::chrono::duration_cast<std::chrono::microseconds>( end_time - start_time );

    std::cout << "sum = " << sum << std::endl;
    std::cout << "execution time: " << elapsed_time.count() << " us" << std::endl;
    return 0;
}
