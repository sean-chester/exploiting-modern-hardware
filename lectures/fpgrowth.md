# Cache-conscious frequent pattern mining (FPGrowth algorithm)

 * Goal today: review a top data management paper (from 2005), co-authored by Intel, using what we've learned

 * What is frequent pattern mining? FPGrowth?
   + a typical approach to solve a data management problem
     - build a large data structure that supports much better (asymptotic?) performance
     - process transformed data instead of raw data
     - we saw this already with LUV! But our data structure was just a resorting of original data.
   + [Frequent Pattern Mining figure](https://www.sciencedirect.com/topics/computer-science/frequent-itemsets)
   + [FPGrowth Algorithm example](https://wimleers.com/sites/wimleers.com/files/FP-Growth%20presentation%20handouts%20%E2%80%94%C2%A0Florian%20Verhein.pdf)

 * Motivation, state-of-the-art (FPGrowth) has substantial room for improvement
   + Uses Intel VTune application to profile. Easier than what we're using (e.g., perf, PAPI)
   + Figure 1: illustration of memory wall
     - Increasing clock speeds (back then) also meant increased penalties (# cycles) for latencies
   + 8% processor utilisation
   + start by determining "hot spots": Table 1
     - What is purpose of Table 2?
       * not as many counters available then: assess memory- or compute-bound
     - What is purpose of Table 3?
       * CPI = 4! Clearly demonstrates poor throughput and therefore room for optmisation
         + likely with data structure redesign

 * Section 3.4, "Memory Managers"
   + what we discussed yesterday: allocate space contiguously for tree
     - in their baseline!
     - their motivation was to reduce malloc()/free() calls, but it also improves spatial locality

 * Figure 3: redesign of data structure to be cache-conscious
   + splitting of hot/cold (counts and nodes and "header links")
   + contiguous allocation of tree nodes
   + tree ordered according to DFS. Why?
     - why not order paths from leaf to root instead, as in traversal?
       * this maintains more contiguity as tree is "conditionally projected" by leaf
         + projections create holes in array
     - what could you try to improve cache performance even more?
       * how would you evaluate if that had been successful?

 * Summary:
   + 5-fold speed-up, including the use of hyperthreads (to be discussed in later lectures)