# Parallel Prefix Sums and Advanced Reductions

## Overview

The _parallel prefix sum_ is a classic training example for learning SIMD/SIMT parallelism. Prefix sums are a surprisingly common algorithmic primitive: we saw it already [when building an adjacency list](../20-simt-graphs/build-graph.cpp).

It is used to train data-parallel thinking because it appears on the surface to be an inherently sequential problem. When does sequentially, it involves `n-1` additions. However, any naive parallel method seems to require `O(n^2)` additions. Seeing how to decompose this into `O(n)` work that can be effectively parallelised, especially with thousands of threads, requires thinking quite differently about the problem.

In this self-paced lab, you have given an efficient sequential implementation and asked to outperform it with a GPU solution that you code up in CUDA. You will go through a few steps to arrive at an excellent solution [1], with hints released every day or two. In the end, you will not only have learned how to solve parallel prefix sums and thinks in a more SIMD-oriented manner, but also have learned a couple new parallel primitives that can be applied to many similar parallel problems.

## Problem Definition

You are given an array of integers:

> `[a_0, a_1, ..., a_{n-1}]`.

You are to calculate the prefix sum, i.e.:

> `[0, a_0, a_0 + a_1, a_0 + a_1 + a_2, ..., âˆ‘a_i - a_{n-1}]`.

(_Note that sometimes the prefix sum starts from `a_0` rather than `0` and then the final term includes `a_{n-1}`._)

## Code Instructions

There are two files in this lesson:
  
  * [prefix-sum.cu](prefix-sum.cu): an implementation of prefix sum in CUDA. A sequential CPU method is provided. You are to create a version that can run on the GPU. 
  * [../15-openmp/unsorted-data.hpp](../15-openmp/unsorted-data.hpp): reusing a c-style 1d vector of random uint32_t values

The code is saved as a CUDA file; so, you will need to compile it with `nvcc` (likely on the Azure instance):

> nvcc -O3 -o ps prefix-sum.cu

(_Note however that you could change the file extension to `.cpp` and compile with `g++` if you want to test out some ideas locally on the CPU before launching any kernels on the GPU._)

## Task

You are already given _two_ efficient sequential implementations, which you can use to verify your understanding of the problem. An in-place algorithm was provided [in a previous lab](../20-simt-graphs/build-graph.cpp) and and out-of-place algorithm is given in [this lab's implementation file](prefix-sum.cu). The latter also serves as a baseline for your work here. You should go through a few design phases (no more than 45 minutes on each) to reach a state-of-the-art solution:

 1) In your initial attempt, simply try to compute the prefix sum on the GPU (not necessarily in a work-efficient manner) and profile it relative to the sequential baseline that you've been given. This will give you a naive GPU baseline and help you practice CUDA.
 2) Next, try to break the dependencies in order to reduce the amount of work. You can try this first with a multicore implementation, if that's easier. The point is to think creatively about how to solve this with data-level parallelism but without using `n^2 / 2` additions. You can refer to the solution [1], but it is good to try to think through the problem yourself first.
 3) Watch for tips released over the coming days on Slack!

## References

[1] Harris et al. (2007) "Chapter 39. Parallel Prefix Sum (Scan) with CUDA." In _GPU Gems 3_. https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda
 