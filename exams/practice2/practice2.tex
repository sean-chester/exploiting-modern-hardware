\documentclass[addpoints,12pt]{exam}

%\usepackage{newtxtext,newtxmath} % times new roman font
\usepackage{url}
\usepackage[dvipsnames]{xcolor}
\usepackage{enumitem}

\usepackage{bm,mathtools}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}

\usepackage{tikz,pgfplots}
\usetikzlibrary{shapes}

\usepackage{titling}
\setlength{\droptitle}{-6em}

\title{Practice Exam \#2\\[0.25em]
\large CSC 485C/586C: Data Management on Modern Computer Architectures}
\date{}

\begin{document}
\maketitle

\vspace{-6.5em}
{\centering
  \hspace{0.05\textwidth}
  \parbox{0.6\textwidth}{%
    Name:\enspace\hrulefill
  }\hspace{2em}
  \parbox{0.25\textwidth}{%
    V00\enspace\hrulefill
  }
}

\bigskip
%\printanswers
\begin{questions}
 \question Please explain the following concepts in 1-3 sentences and/or code snippets and/or a small illustration.  An excellent answer does not have to be long, just precise.\\{\em Guide: 2 minutes each} 

 \medskip
 
 \begin{parts}
   \part[1] Cache Coherency
     \begin{solution}[6em]
     \end{solution}
   
   \part[1] Data-level Parallelism
     \begin{solution}[6em]
     \end{solution}
   
   \part[1] False Sharing
     \begin{solution}[6em]
     \end{solution}
   
   \part[1] Synchronisation
     \begin{solution}[6em]
     \end{solution}
   
   \part[1] Vectorisation
     \begin{solution}[6em]
     \end{solution}
 \end{parts}
 
 \newpage
 \question The plot below shows the relative performance (as measured in execution time) of two parallel algorithms (called "My Algorithm" and "State of the Art") and a sequential baseline ("Seq. Baseline") on a fixed input. It is a {\em parallel scalability plot} that illustrates how performance changes as the number of threads varies, although it shows time rather than speed-up.
Answer the following questions that analyse this figure:\\
{\em Guide: 10 min total}

\begin{figure}[h!]
  \centering
  \input{tikz/work-eff-chart}
\end{figure}

   \begin{parts}
       \part[2] Which parallel algorithm is more work-efficient? Explain how you arrived at this conclusion.
           \begin{solution}[8em]
           \end{solution}

       \part[2] Which algorithm exhibits the best parallel scalability? Justify your response.
           \begin{solution}[8em]
           \end{solution}

       \part[2] What is the overall message (a.k.a., purpose, or significance) of the plot?
           \begin{solution}[8em]
           \end{solution}
   \end{parts}
 
 
  \question[8] A ``Palentine's Card'' is a warm greeting card that one gives to a friend on 14 February. Below we have a data structure to define a set of Palentine's Cards and an algorithm to count how many pairs have the same sender {\em and} recipient, i.e., cases where one person gave multiple cards to the same pal. Sadly, the implementation suffers from poor cache performance. Rewrite both the implementation and the data structures to optimise cache performance. (Pseudocode or annotations is fine; proper syntax is not evaluated, so long as the intent is clear.)\\
{\em Guide: 15 min}
  
   \bigskip
    \begin{minipage}{.4\textwidth}
      \begin{verbatim}
struct palentine
{
  std::string sender_name;
  std::string recipient_name;
  std::string message;
};

// overload == for palentine
bool operator == ( /*...*/ )
{
    // return true if both sender
    // and recipient match
}

std::vector< palentine > cards;
      \end{verbatim}
    \end{minipage}
    \hfill
    \begin{minipage}{.5\textwidth}
      \begin{verbatim}
template < typename T >
auto num_matching_cards( T const& cards )
{
    auto const n = cards.size();
    auto num_matches = 0llu;

    for( auto i = 0u; i < n; ++i )
    {
        for( auto j = i + 1; j < n; ++j )
        {
            if( cards[ i ] == cards[ j ] )
                ++num_matches;
        }
    }
    return num_matches;
};
      \end{verbatim}
    \end{minipage}
    

      \begin{solution}[15em]

Full marks for:
\begin{itemize}
  \item Increasing spatial locality by decreasing working set size by:
    \begin{itemize}
      \item converting AoS to SoA by taking the ``cold'' \texttt{std::string message} out of the main struct
      \item replacing the \texttt{std::string *\_name}'s with pointers to a struct containing the names (preferably organised in a vector)
    \end{itemize}
  \item Increasing temporal locality by:
    \begin{itemize}
      \item Tiling the outer loop over $i$
    \end{itemize}
  \item Other useful optimisations in lieu of those above
\end{itemize}
A bonus mark will be given if the pointers to the structs are moreover replaced by an index into the array of person structs, clarifying the assumptions about the number of distinct persons. This can decrease the size of the hot data even further.

   \bigskip
    \begin{minipage}{.35\textwidth}
      \begin{verbatim}
struct person
{
  std::string name;
};

std::vector< person > people;

struct header
{
  uint32_t sender_id;
  uint32_t recipient_id;
};

struct cards
{
  using namespace std;

  vector< header > headers;
  vector< string > messages;

  auto size() const
  {
    return headers.size();
  }
};
      \end{verbatim}
    \end{minipage}
    \hfill
    \begin{minipage}{.6\textwidth}
      \begin{verbatim}
template < typename T >
auto num_matching_cards( T const& cards )
{
    auto const n = cards.size();
    auto const tile_size = 4u;
    auto num_matches = 0llu;

    for(auto i=0u; i<n; i += tile_size )
    {
      for(auto j=i+1; j < n; ++j)
      {
        for(auto k=0u; k < tile_size; ++k)
        {
          if( cards.headers[ i ]
           == cards.headers[ j ] )
            ++num_matches;
        }
      }
    }
    return num_matches;
};



      \end{verbatim}
    \end{minipage}

      \end{solution}
    
    \question Answer the following two questions on the data structure below:\\
{\em Guide: 5 min}

\begin{verbatim}
struct box_of_chocolates
{
    uint16_t num_milk_chocolates;
    uint16_t num_dark_chocolates;
    uint8_t  num_white_chocolates;
    uint32_t box_size; // volume in cubic millimeters
};
\end{verbatim}

      \begin{parts}
         \part[2] Considering alignment, how would you change this struct without changing any data types so that your working set size was reduced?\\
      
      \begin{solution}[8em]

({\em Note that this question contained a typo. The milk chocolates were supposed to only use 1 byte. Obviously I had a hard time convincing myself that $2^8$ milk chocolates are quite enough\ldots})

\medskip
With 2B of milk chocolates, the struct above contains 3B of padding between the white chocolates and the box size; thus the total struct uses 12B. With 1B of milk chocolates, there is also another 1B of padding between the milk and dark chocolates, so it still requires 12B.

\medskip
Ordering the fields descending by the size of their data types removes the need for padding. With 2B of milk chocolates, this still requires 9B which will round up to 12B (to fit a ``word''); with 1B of milk chocolates, this now requires 8B, which decreases the working set size by 33\%.
      \end{solution}

         \part[1] How would you verify that your changes had reduced the working set size?\\
      
      \begin{solution}[5em]
Measure it directly. There are many ways to do this, but the simplest is to call `sizeof()` inside a \texttt{c++} application.

\medskip
You could also check the assembly that is generated, print a bunch of them to a binary file and measure the file size, or, in a more indirect sense, measure if there was a speed up in running time.
      \end{solution}
    
      \end{parts}
\end{questions}

\vfill
\begin{minipage}{.2\textwidth}\hphantom{xxxxxxxxxxx}\end{minipage}
\gradetable[h][questions]

\end{document}
