\documentclass[addpoints,12pt]{exam}

%\usepackage{newtxtext,newtxmath} % times new roman font
\usepackage{url}
\usepackage[dvipsnames]{xcolor}
\usepackage{enumitem}

\usepackage{bm,mathtools}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}

\usepackage{tikz,pgfplots}
\usetikzlibrary{shapes}

\usepackage{titling}
\setlength{\droptitle}{-6em}

\title{Practice Exam \#2\\[0.25em]
\large CSC 485C/586C: Data Management on Modern Computer Architectures}
\date{}

\begin{document}
\maketitle

\vspace{-6.5em}
{\centering
  \hspace{0.05\textwidth}
  \parbox{0.6\textwidth}{%
    Name:\enspace\hrulefill
  }\hspace{2em}
  \parbox{0.25\textwidth}{%
    V00\enspace\hrulefill
  }
}

\bigskip
%\printanswers
\begin{questions}
 \question Please explain the following concepts in 1-3 sentences and/or code snippets and/or a small illustration.  An excellent answer does not have to be long, just precise.\\{\em Guide: 2 minutes each} 

 \medskip
 
 \begin{parts}
   \part[1] Cache Coherency
     \begin{solution}[6em]
     \end{solution}
   
   \part[1] Data-level Parallelism
     \begin{solution}[6em]
     \end{solution}
   
   \part[1] False Sharing
     \begin{solution}[6em]
     \end{solution}
   
   \part[1] Synchronisation
     \begin{solution}[6em]
     \end{solution}
   
   \part[1] Vectorisation
     \begin{solution}[6em]
     \end{solution}
 \end{parts}
 
 \newpage
 \question The plot below shows the relative performance (as measured in execution time) of two parallel algorithms (called "My Algorithm" and "State of the Art") and a sequential baseline ("Seq. Baseline") on a fixed input. It is a {\em parallel scalability plot} that illustrates how performance changes as the number of threads varies, although it shows time rather than speed-up.
Answer the following questions that analyse this figure:\\
{\em Guide: 10 min total}

\begin{figure}[h!]
  \centering
  \input{tikz/work-eff-chart}
\end{figure}

   \begin{parts}
       \part[2] Which parallel algorithm is more work-efficient? Explain how you arrived at this conclusion.
           \begin{solution}[8em]
           \end{solution}

       \part[2] Which algorithm exhibits the best parallel scalability? Justify your response.
           \begin{solution}[8em]
           \end{solution}

       \part[2] What is the overall message (a.k.a., purpose, or significance) of the plot?
           \begin{solution}[8em]
           \end{solution}
   \end{parts}
 
 
  \question[8] A ``Palentine's Card'' is a warm greeting card that one gives to a friend on 14 February. Below we have a data structure to define a set of Palentine's Cards and an algorithm to count how many pairs have the same sender {\em and} recipient, i.e., cases where one person gave multiple cards to the same pal. Sadly, the implementation suffers from poor cache performance. Rewrite both the implementation and the data structures to optimise cache performance. (Pseudocode or annotations is fine; proper syntax is not evaluated, so long as the intent is clear.)\\
{\em Guide: 15 min}
  
   \bigskip
    \begin{minipage}{.4\textwidth}
      \begin{verbatim}
struct palentine
{
  std::string sender_name;
  std::string recipient_name;
  std::string message;
};

// overload == for palentine
bool operator == ( /*...*/ )
{
    // return true if both sender
    // and recipient match
}

std::vector< palentine > cards;
      \end{verbatim}
    \end{minipage}
    \hfill
    \begin{minipage}{.5\textwidth}
      \begin{verbatim}
template < typename T >
auto num_matching_cards( T const& cards )
{
    auto const n = cards.size();
    auto num_matches = 0llu;

    for( auto i = 0u; i < n; ++i )
    {
        for( auto j = i + 1; j < n; ++j )
        {
            if( cards[ i ] == cards[ j ] )
                ++num_matches;
        }
    }
    return num_matches;
};
      \end{verbatim}
    \end{minipage}
    

      \begin{solution}[15em]

Full marks for:
\begin{itemize}
  \item Increasing spatial locality by decreasing working set size by:
    \begin{itemize}
      \item converting AoS to SoA by taking the ``cold'' \texttt{std::string message} out of the main struct
      \item replacing the \texttt{std::string *\_name}'s with pointers to a struct containing the names (preferably organised in a vector)
    \end{itemize}
  \item Increasing temporal locality by:
    \begin{itemize}
      \item Tiling the outer loop over $i$
    \end{itemize}
  \item Other useful optimisations in lieu of those above
\end{itemize}
A bonus mark will be given if the pointers to the structs are moreover replaced by an index into the array of person structs, clarifying the assumptions about the number of distinct persons. This can decrease the size of the hot data even further.

   \bigskip
    \begin{minipage}{.35\textwidth}
      \begin{verbatim}
struct person
{
  std::string name;
};

std::vector< person > people;

struct header
{
  uint32_t sender_id;
  uint32_t recipient_id;
};

struct cards
{
  using namespace std;

  vector< header > headers;
  vector< string > messages;

  auto size() const
  {
    return headers.size();
  }
};
      \end{verbatim}
    \end{minipage}
    \hfill
    \begin{minipage}{.6\textwidth}
      \begin{verbatim}
template < typename T >
auto num_matching_cards( T const& cards )
{
    auto const n = cards.size();
    auto const tile_size = 4u;
    auto num_matches = 0llu;

    for(auto i=0u; i<n; i += tile_size )
    {
      for(auto j=i+1; j < n; ++j)
      {
        for(auto k=0u; k < tile_size; ++k)
        {
          if( cards.headers[ i ]
           == cards.headers[ j ] )
            ++num_matches;
        }
      }
    }
    return num_matches;
};



      \end{verbatim}
    \end{minipage}

      \end{solution}
    
    \question You are given a set of randomly located unit (i.e., of size $1\times1$) squares in the Euclidean plane and are to determine how many of them intersect each other. Please write a work-efficient algorithm that scales well with parallelism to solve this task. It should do less work than the naive quadratic solution that compares every point to every other point.

Your best strategy will be to create a two-step algorithm. In the first step, you should preprocess the data. In the second step you should operate on the preprocessed data to solve the problem efficiently.

The focus of this question is on how you expose parallelism. You are free to describe the algorithm however you want (e.g., pseudocode, c++, a mixture thereof), but it should be specific enough that it is clear what are the distinct parallel tasks and what synchronisation and/or contention occurs.\\
{\em Guide: 20 min}

      \begin{solution}[8em]
      \end{solution}
\end{questions}

\vfill
\begin{minipage}{.2\textwidth}\hphantom{xxxxxxxxxxx}\end{minipage}
\gradetable[h][questions]

\end{document}
