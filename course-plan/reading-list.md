# Reading List: CSC 586C (Data Management on Modern Hardware)

 - Midterm 1
 - Midterm 2


 - Course outline, motivation, objectives, ILO's, in-scope versus topical
   + DB background, what is query processing, what is in scope? Shared memory.
 - Herb Sutter articles, motivation, relevance, memory wall, transistor size, power wall
   * Sutter (2005). _The Free Lunch Is Over: A Fundamental Turn Toward Concurrency in Software_. http://www.gotw.ca/publications/concurrency-ddj.htm
   * Sutter (2012). _Welcome to the Jungle: Or, A Heterogeneous Supercomputer in Every Pocket_. https://herbsutter.com/welcome-to-the-jungle/
 - c++ functors, templates, const, ref/ptr, xval/rval, inlining, STL, namespaces
   +  Hot spots and profiling, c++ timing libraries, microbenchmarking


## Cache-conscious Software and Algorithms
   * Jacobs (2009). "The Pathologies of Big Data." _Communications of the ACM_ 52(8). https://dl.acm.org/doi/10.1145/1536616.1536632 

   Our first example of experiments showing how memory access patterns and data layout dramatically affect performance. Will be discussed in class on 15 Jan, with a focus on Figure 1 and Figure 3. We will also discuss more broadly the concepts of compute-bound versus memory-bound implementations and the memory wall.

   * Intel (2019). _IntelÂ® 64 and IA-32 Architectures Optimization Reference Manual_, Appendix B.1: "Top-Down Analysis Method." https://software.intel.com/en-us/download/intel-64-and-ia-32-architectures-optimization-reference-manual
   
   Introduces a general methodology for architecture-conscious code profiling for performance. We will in class on 17 Jan use the events listed in Appendix B.2 and learn how to apply this method to isolate performance bottlenecks and drive algorithmic design. This methodology will be used throughout the course to verify algorithmic claims.

   * Drepper (2007). _What Every Programmer Should Know About Memory_, Chapter 3: "CPU Caches" until 3.3 + Chapter 3.3.2 "Measurement of Cache Effects." https://people.freebsd.org/~lstewart/articles/cpumemory.pdf

   Describes cache in terms of how it affects your programming. To be discussed in class 21 Jan. We will see how to reproduce one of the plots.

   * Drepper (2007), Chapter 6.2.1 "Optimizing Level 1 Data Cache Access."

   Uses Chapter 3.3 to optimise matrix optimisations by an order of magnitude. We will discuss and try to reproduce this 22 Jan.

   * Chilimbi et al. (2000). "Making Pointer-Based Data Structures Cache Conscious." _IEEE Computer_ 33(12). http://ezproxy.library.uvic.ca/login?url=https://ieeexplore.ieee.org/document/889095

   Extends Chapter 6.2.1 of Drepper to pointer-based structures, namely search trees. (Matrices, by contrast, are _contiguous_ data structures.) To be discussed 24 Jan.

   * Ghoting et al. (2005). "Cache-conscious Frequent Pattern Mining on a Modern Processor." _VLDB_. http://ezproxy.library.uvic.ca/login?url=https://dl.acm.org/doi/10.5555/1083592.1083660

   High-impact paper with Intel that applies what we've learned by this point to a classic data mining problem (frequent itemset mining). To be analysed 28 Jan.

   * Cohen (2018). "Maximize Cache Performance with this One Weird Trick: An Introduction to Cache-Oblivious Data Structures." Blog Post: https://rcoh.me/posts/cache-oblivious-datastructures/. Accessed: 12 January 2020.

   Blog post that summarises a linked research paper by Demaine (2002). Introduces a theoretical model (cache-oblivious algorithms) that captures the ideas we've investigated until now. May be skipped depending on time.

   * Li & Patel (2013). "BitWeaving: Fast Scans for Main Memory Data Processing." _SIGMOD_. http://pages.cs.wisc.edu/~jignesh/publ/BitWeaving.pdf

   Uses "bit-level parallelism" to optimise cache to achieve "bare metal speed." May be skipped depending on time.



 - ILP, micro- vs macro-instructions

 - fine-grained vs coarse-grained parallelism

 - Branch prediction, pipeline flush, branch-free code

 - alignment, tlb's

 - Threading models (MPI, c++ threads, OpenMP)

 - Multicore, multi-socket, shared cache, NUMA effects, cache coherency, hyperthreads

 - AVX, SIMD, vectorisation, measuring AVX usage

 - Designing for data-level parallelism (mention thread-level)

 - Isolated testing of ideas, conditional compilation, plots

 - QSkyline as example of tiling for multi-core; sync barriers
   * Chester et al. (2015) "Scalable parallelization of skyline computation for multi-core processors." _ICDE_. http://sean-chester.github.io/assets/preprints/chester_icde2015_mcsky.pdf

 - NUMA islands, EPFL paper
   * Porobic et al. (2012) "OLTP on Hardware Islands". _PVLDB_ 5(11). http://vldb.org/pvldb/vol5/p1447_danicaporobic_vldb2012.pdf

 - thread blocks, warps, and step-locking

 - context switching + latency hiding + thread population

 - texture cache, shared memory, thread-local memory, PCIe, CUDA streams, iGPU

 - GPU Overview, motivation, integrated analytics, history, overall arch, SIMT, many weak cores vs few fat cores

 - Thrust + CUDA + OpenCL + nvcc + nvidia profiler

 - Parallel Scan / tree + butterfly mixing
   * Harris et al. (2007) "Chapter 39. Parallel Prefix Sum (Scan) with CUDA." _GPU Gems 3_. https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda

 - SkyAlign?

 - Processor-in-memory technology
   * Balkesen et al. (2018). "RAPID: In-Memory Analytical Query Processing Engine with Extreme Performance per Watt." _SIGMOD_. ezproxy.library.uvic.ca/login?url=https://dl.acm.org/doi/abs/10.1145/3183713.3190655
   * Sindhu et al. (2018). "Data processing unit for stream processing" _US Patent_ #20190012350A1. https://patents.google.com/patent/US20190012350A1/en
   * Zois et al. (2018). "Massively parallel skyline computation for processing-in-memory architectures." _PACT_. https://ezproxy.library.uvic.ca/login?url=https://dl.acm.org/doi/10.1145/3243176.3243187

 - configurable spatial accelerator
   * Fleming et al. (2016). "Processors, methods, and systems with a configurable spatial accelerator" _US Patent_ #20180189231A1. https://patents.google.com/patent/US20180189231A1/en
   * https://en.wikichip.org/wiki/intel/configurable_spatial_accelerator

 - FPGA skyline paper
 - quantum?
   * qubits, motivation, hype, computational model
   * simulator
   * some algorithmic paper

 - heterogeneous parallelism?
 - wrap up course, clouds, revisit Sutter?
