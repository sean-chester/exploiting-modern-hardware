#  Profiling with the Linux Perf Tool

## Overview

This guide is meant to help you directly confirm hypotheses about what sort of bottlenecks (if any!) are throttling you applications. Note that these tips are specifically designed for the Linux tool, `perf`, but the concepts should transfer to any
tool that allows you to measure hardware performance counters (e.g., [Intel VTune](https://software.intel.com/en-us/parallel-studio-xe/choose-download/student-windows) and [PAPI](https://icl.utk.edu/papi/)).

Intel machines have built-in counters to measure architectural events, such as cache misses. They run constantly, even if you aren't aware that they are there. You simply need a tool to measure them. Appendix B of the Intel Optimisation Guide [1] describes them in some detail.

When it comes to something like cache-conscious design, you can directly measure your success! Few know this, though.

I personally have not seen these described at a level appropriate for a classroom setting. The assumption in all documentation is that you are already a proficient magician when it comes to low-level optimisation, not in the process of becoming one! I'm trying to bridge that gap here.

`perf` is part of the `linux-tools` package on distros like Ubuntu. However, it is the existence of the hardware events that makes this possible, not the specific tool. Anything that can read hardware counters can answer questions like, "is this program memory bound?" and, by extension, "should I optimise my data structures or my control flow?"


## Basic Usage

Before beginning, you should note that your system administrator (you, if it's your computer!) decides whether any user can read hardware counters or not. By default, it requires root access (i.e., `sudo`). If you don't have root access and you can't read counters, you need to contact your administrator and ask them to enable it. Your education depends on it!

The `perf` tool provides a number of options, including `record`, `report`, `stat`, etc. You can read more about these at [2]. Here, I will focus on `stat`, which prints to the terminal the hardware counter statistics for a given program. For example, if you run:

> sudo perf stat ./program-name 

This will print default, common statistics such as instruction per cycle (IPC) and branch misprediction rate. An indicative response is:

```
 Performance counter stats for './ilp':

         22,163.17 msec task-clock                #    0.998 CPUs utilized          
               892      context-switches          #    0.040 K/sec                  
                 7      cpu-migrations            #    0.000 K/sec                  
               130      page-faults               #    0.006 K/sec                  
    64,310,833,933      cycles                    #    2.902 GHz                    
    40,033,829,176      instructions              #    0.62  insn per cycle         
     8,005,897,793      branches                  #  361.225 M/sec                  
           330,812      branch-misses             #    0.00% of all branches        

      22.213487036 seconds time elapsed

      22.157538000 seconds user
       0.007996000 seconds sys
```

If you run it in "detailed" mode, you will get slightly different, but more detailed information, such as cache miss rates for L1 and last-level-cache (LLC):

> sudo perf stat -d ./program-name

```
 Performance counter stats for './ilp':

         22,066.02 msec task-clock                #    1.000 CPUs utilized          
               100      context-switches          #    0.005 K/sec                  
                 0      cpu-migrations            #    0.000 K/sec                  
               129      page-faults               #    0.006 K/sec                  
    64,277,728,206      cycles                    #    2.913 GHz                      (49.97%)
    40,027,648,190      instructions              #    0.62  insn per cycle           (62.48%)
     8,007,377,881      branches                  #  362.883 M/sec                    (62.49%)
           338,252      branch-misses             #    0.00% of all branches          (62.51%)
        10,886,587      L1-dcache-loads           #    0.493 M/sec                    (62.53%)
         1,073,802      L1-dcache-load-misses     #    9.86% of all L1-dcache hits    (62.52%)
           443,950      LLC-loads                 #    0.020 M/sec                    (50.00%)
           201,291      LLC-load-misses           #   45.34% of all LL-cache hits     (49.98%)

      22.068858384 seconds time elapsed

      22.067341000 seconds user
       0.000000000 seconds sys
```

This is quite helpful at the top-level of the Intel top-down analysis method (Appendix B.1 in [1]), as you can immediately determine whether branch misprediction or memory access patterns seem to be the major problem. You can also immediately see IPC to determine whether you are memory-bound (IPC<1) or have more complex challenges (IPC>1).

Note that rates aren't enough. You must consider absolute values as well. In the above example, the cache miss ratio on L3 (last-level cache) is 45%. That doesn't necessarily mean it is a bottleneck for the system overall, because there are only 444k loads from LLC anyway.


## Detailed Usage

When you want to dig deeper or you have more specific questions, you should query specific counters. For example, if you want to know if AVX/SSE/SIMD was utilised, it is best to query those counters specifically. For this, you should first identify the relevant counters and then measure them.

### Identifying counters

The following command shows you a jargonistic list of all the hardware "events" you can read with the `perf` tool:

> sudo perf list

The events are categorised by type, e.g., related to floating point arithmetic or memory operations. This admittedly gets difficult, as you have to understand a lot of jargon to determine what a counter like "OFF_CORE_XXX" means. If you are at the stage of reading this documentation, PLEASE do not hesitate to ask me for help. I'm impressed already by your efforts, and I know from experience the learning curve to being able to express oneself in this jargon.

### Measuring specific counters

If you have a list of counters that you want to measure, use the `-e` (events) flag for `perf` with a comma-separated list of events. E.g., if you want to measure "cycles" and "instructions":

> sudo perf stat -e cycles,instructions ./program-name

For some combinations, you will also obtain additional relative statistics. The example above would also print out the IPC, since you've measured both arguments necessary for calculating it.


## Mac OS Equivalent

If working on a mac, you likely use the _XCode_ IDE. It is freely available in the App Store, but requires an up-to-date OS (e.g., Catalina) and an Apple ID. _XCode_ is shipped with another application called _Instruments_, which [can be used to read performance counters](https://help.apple.com/instruments/mac/current/#/devc75b9dd9).

To profile your code, launch _Instruments_ through the `Product`→`Profile` menu and choose the _Counters_ template from the wizard menu that appears. This will attach the performance counter profiler to the target that you had already set up in your _XCode_ project.  From that point, [this tutorial](https://www.robertpieta.com/counters-in-instruments/) documents quite accessibly how to select particular counters or "formulae." You select counters from the `File`→`Recording Options` menu item.

I have confirmed this in _XCode_ 6 on _Mac OS Catalina_; however, the counter stats that I obtained were nonsensical, as also [reported recently on StackOverflow](https://stackoverflow.com/q/59174636/2769271). If using _Instruments_ for profiling in this course, please confirm that you are getting reasonable statistics for your application. You've been warned not to trust it blindly.


## Conclusion

The linux `perf` tool (and comparable alternatives such as Intel VTune) can elevate your profiling skills to another planet, but the learning curve is steep because of the jargon and the lack of educational resources. Take the plunge during this semester and I'll do everything I can to support you!

Nothing informs decisions quite like data!


## References

[1] Intel. (2019) _Intel® 64 and IA-32 Architectures Optimization Reference Manual_ https://software.intel.com/en-us/download/intel-64-and-ia-32-architectures-optimization-reference-manual

[2] Gregg. (2019) "Linux perf Examples." http://www.brendangregg.com/perf.html. Accessed: 6-Feb-2019.
