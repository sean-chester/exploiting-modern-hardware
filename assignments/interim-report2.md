# CSC 485C/586C Term Project: Interim Report 2

*An application of the multicore course concepts to improve upon your single-core performance*


## Objective

In your first interim report, you developed a well-optimised single-threaded baseline for your data management problem, hopefully alleviating memory latencies and setting the stage for effective parallelism. In this second interim report, you are welcome (and encouraged!) to continue optimising that baseline, but you should also expose and exploit parallelism now. Your overall objective is to gain a substantial speed-up over your optimised baseline via (multicore and/or SIMD) parallelism.

You should submit a revision to your report that retains critical details from before but also now explains _how_ and _how well_ you have exposed and leveraged parallelism.


## Submission

Each group should try to apply some concepts from the course so far in order to obtain a >4x speed-up over their optimised baseline, using 6 cores of an [Intel® Xeon® Processor E5-2690 v4](https://ark.intel.com/content/www/us/en/ark/products/91770/intel-xeon-processor-e5-2690-v4-35m-cache-2-60-ghz.html) (broadwell) processor. You are advised to also consider _work-efficiency_ as a design consideration. You should re-submit your ongoing report with your new findings, adhering to the evaluation rubric below.

The report should aim for roughly twelve double-column pages, excluding front matter and back matter (e.g., reference lists, non-critical appendices). Six pages is too few and twenty-five pages is too many. Length does not correlate strongly with grade.

Additionally, any resources needed to recreate the experiment results should be provided, e.g., by a time-sensitive link to a cloneable `git` repository. It is highly likely that this code will be run on a 6-core Azure instance to verify the results.


## Evaluation

Recall that in addition to this evaluation, any improvements to the report that sufficiently improve upon the evaluation criteria of the first interim report can lead to an increased grade thereon. Similarly, subsequent submissions that improve upon these evaluation criteria can improve your score in the future for this second interim report. As before, the evaluation will be _strict_ with _extensive_ formative feedback.

The criteria are listed below, along with their evidence of fulfillment. It is advisable to have a section in your report corresponding to each criterion, as this will make your contributions more evident. You will also want to retain (and perhaps revise) those sections from the previous report that are important for understanding your new contributions.

### Quality of Baseline

*The value of parallel speed-up depends greatly on *what* you're speeding up. Describe how your single-threaded baseline is algorithmically optimised*

A good baseline method will:
  - have a competitive asymptotic complexity
  - run efficiently on practical input instances
  - be difficult to accelerate without using parallelism

The difference between a 2 and 1 on this criterion will be the clarity and compellingness with which the baseline is demonstrated to be *competitive*.

### Parallel Algorithm Description

*In a parallel data management research paper, the methods section clearly articulates how parallelism is exposed*

In this interim report, you should augment your algorithmic description with a discussion of how it is made parallel:
  - make the parallelism in the algorithmic control flow clear
  - describe clearly how race conditions on shared data structures are handled

The difference between a 2 and 1 on this criterion will be how clearly you illustrate the parallelisation of the algorithm and how you've managed contention between threads. As a tip, pseudocode can be really helpful, especially if it's limited to <15 lines.

### Experiment Setup

*In a parallel data management research paper, you also need to define experiments that evaluate the trade-offs that the parallelisation creates*

In your report, you should describe how you have studied the effect of increasing parallelism and, if relevant, why it is sub-linear

The different between a 2 and 1 on this criterion will be the choice of experiments that demonstrate why parallelism is less than perfect, or, in the case of a 6x speed-up, why it is perfect.

### Parallel Scalability

*In any data management research paper, raw performance is the ultimate arbiter*

In your report, you should demonstrate a clear comparison between the performance before you apply parallelism and afterwards, preferably as a function of the amount of parallelism invoked. Probably, this information will be reported in terms of a table or a plot. As a tip, if you can vary input parameters, such as the number of threads, you will be able to make the case of scalability more clearly.

The difference between a 2 and a 1 on this criterion will be whether you obtain a threshold of 4x speed-up. The difference between a 1 and a 0 is whether you obtain any speed-up at all.

### Evidence of work efficiency

*An oft overlooked element of parallelism is work-efficiency. You should also demonstrate that your algorithm is competitive with the single-threaded state-of-the-art*

In your report, you should indicate:
  - how you intend to measure work efficiency (preferably 2+ independent metrics)
  - that your parallel algorithm has comparable work-efficiency to the optimised, single-threaded baseline

The difference between a 2 and a 1 on this criterion is how convincing is your evidence that you have a work-efficient parallel algorithm.

### Overall analysis and evidence to support design decisions

*The point of all this is to make things faster and more scalable (less resources, more data, more speed, more interactive, etc.)*

In your report, you should indicate:
  - clearly, what design decisions you have made to the original data structures and/or algorithm
  - some evidence to directly show that those design decisions are responsible for the speed-ups demonstrated in the previous rubric criteria

The difference between a 2 and a 1 on this criterion is whether you have convincing supporting evidence that correlates directly with design choices rather than just overall execution time.

## Postscript

Your next interim report will add GPU parallelism with a [Tesla Volta V100 GPU](https://images.nvidia.com/content/technologies/volta/pdf/volta-v100-datasheet-update-us-1165301-r5.pdf). If you are able to expose enough parallelism already at this stage to saturate 10's of thousands of threads, you will find the next step easier.
