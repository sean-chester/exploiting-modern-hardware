# CSC 485C/586C Term Project: Interim Report 3

*A foray into replicating your multi-core performance with GPGPU computing*


## Objective

In your first tow interim reports, you developed a well-optimised single-threaded baseline for your data management problem and then parallelised it with either multi-core parallelism, SIMD parallelism, or both. Now you will really stretch the _width_ of the parallelism that you have exposed by porting it to a GPU.

You should submit a second revision to your report that retains critical details from before but also now explains _how_ and _how well_ you have exposed and leveraged parallelism for the GPU.


## Submission

Each group should try to apply some concepts from the course so far in order to match their multi-core/SIMD performance, using an [NVIDIA Tesla V100 GPU](https://www.nvidia.com/en-us/data-center/v100/) with an impressive 16 GB of memory. You have massive parallelism at your disposal, but you will likely need to still consider _work-efficiency_ as a design consideration if you want to match the performance of your highly-optimised CPU solution. You should re-submit your ongoing report with your new findings, adhering to the evaluation rubric below.

The report should aim for roughly sixteen double-column pages, excluding front matter and back matter (e.g., reference lists, non-critical appendices). Eight pages is too few and twenty-five pages is too many. Length does not correlate strongly with grade.

Additionally, any resources needed to recreate the experiment results should be provided, e.g., by a time-sensitive link to a cloneable `git` repository. It is highly likely that this code will be run on the V100 of the Azure instance to verify the results.


## Evaluation

Recall that in addition to this evaluation, any improvements to the report that sufficiently improve upon the evaluation criteria of the first or second interim report can lead to an increased grade thereon. Similarly, final project submissions that improve upon these evaluation criteria can improve your score in the future for this third interim report. As before, the evaluation will be _strict_ with _extensive_ formative feedback.

The criteria are listed below, along with their evidence of fulfillment. It is advisable to have a section in your report corresponding to each criterion, as this will make your contributions more evident. You will also want to retain (and perhaps revise) those sections from the previous report that are important for understanding your new contributions.

### Discussion of Computational Models

*In this course, we have learned how to design programs in several parallel computational models. You already knew the sequential model (although hopefully you learned it in greater detail). You now also know multi-core, SIMD, and GPGPU computing. In roughly one page, you should compare and contrast all four of these models to each other.*

A good discussion will:
  - discuss both similarities _and_ differences of models
  - present the information in a clear, digestible form
  - be precise; cover the main points

The difference between a 2 and 1 on this criterion will be the clarity and completeness of the discussion.

### GPGPU Algorithm Description

*Your methods section should expand to now also clearly articulate how GPU parallelism is exposed*

As in the previous report, you should describe how you made your algorithm appropriate for the GPU:
  - make the parallelism in the algorithmic control flow clear
  - describe clearly how race conditions on shared data structures are handled

The difference between a 2 and 1 on this criterion will be how clearly you illustrate the parallelisation of the algorithm and how you've managed branch divergence. As a tip, pseudocode can be really helpful, especially if it's limited to <15 lines.

### Evidence of Correctness

*For experiments to be trustworthy, it is important to demonstrate that the implementations are correct*

In your report, you should provide evidence that shows the GPGPU implementation produces solutions that are as correct as the single-threaded baseline.

The different between a 2 and 1 on this criterion will be the compellingness of the evidence.

### Raw GPU Performance

*In any data management research paper, raw performance is the ultimate arbiter*

In your report, you should demonstrate a clear comparison between the performance of your GPU implementation relative to your now-very-good CPU baseline. 

The difference between a 2 and a 1 on this criterion will be whether you obtain a threshold of matching with the GPU your multi-core/SIMD performance. The difference between a 1 and a 0 is whether your application runs and produces the correct results.

### Reproducibility

*Whether somebody is likely to use your research results largely comes down to how easy it is!*

In your report, you should indicate:
  - how to run your code on the GPU as well as the CPU
  - how to generate the plots in your report (perhaps even by including a script that does it automatically!)

The difference between a 2 and a 1 on this criterion is whether the TA can reproduce your results in under 10 minutes. The difference between a 1 and a 0 is whether they can do it in a reasonable amount of time at all.

### Overall analysis and evidence to support design decisions

*The point of all this is to make things faster and more scalable (less resources, more data, more speed, more interactive, etc.)*

In your report, you should indicate:
  - clearly, what design decisions you have made to the original data structures and/or algorithm
  - some evidence to directly show that those design decisions are responsible for the speed-ups demonstrated in the previous rubric criteria

The difference between a 2 and a 1 on this criterion is whether you have convincing supporting evidence that correlates directly with design choices rather than just overall execution time.

## Postscript

Your final project submission will refine this interim report and take into account the feedback.
